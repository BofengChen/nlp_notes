{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# jieba分词的[github](https://github.com/fxsjy/jieba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=black size=3>主要功能</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分词"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=green size=3>关于参数：cut_all默认为false，HMM默认为true.\n",
    " HMM如果不开启，像”光之翼“这种词库中未出现的词，可能无法分词，另一种解决办法是，将这个词汇添加到词库</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full mode: 上汽/ 集团/ 的/ 光之翼/ 车型/ / / 销量/ 如何/ / \n",
      "default:上汽/集团/的/光之翼/车型/，/销量/如何/？\n",
      "default_01:上汽/集团/的/光之翼/车型/，/销量/如何/？\n",
      "add the unknow word:上汽/集团/的/光之翼/车型/，/销量/如何/？\n"
     ]
    }
   ],
   "source": [
    "# jieba.cut 方法接受三个输入参数: 需要分词的字符串；cut_all 参数用来控制是否采用全模式；HMM 参数用来控制是否使用 HMM 模型\n",
    "# 待分词的字符串可以是 unicode 或 UTF-8 字符串、GBK 字符串。注意：不建议直接输入 GBK 字符串，可能无法预料地错误解码成 UTF-8\n",
    "# encoding=utf-8\n",
    "import jieba\n",
    "str_1 = '上汽集团的光之翼车型，销量如何？'\n",
    "seg_list = jieba.cut(str_1, cut_all=True) #　全模式\n",
    "print \"full mode: \" + \"/ \".join(seg_list)\n",
    "seg_list = jieba.cut(str_1, cut_all=False) # 精确模式，HMM默认开启\n",
    "print \"default:\" + \"/\".join(seg_list)\n",
    "seg_list = jieba.cut(str_1,cut_all=False, HMM=False) # HMM未开启的情况下\n",
    "print \"default_01:\" + \"/\".join(seg_list)\n",
    "# 加词语\n",
    "jieba.add_word('光之翼')\n",
    "seg_list = jieba.cut(str_1,cut_all=False, HMM=False)\n",
    "print \"add the unknow word:\" + \"/\".join(seg_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search:上汽/集团/的/光之翼/车型/，/销量/如何/？\n"
     ]
    }
   ],
   "source": [
    "# jieba.cut_for_search 方法接受两个参数：需要分词的字符串；是否使用 HMM 模型。该方法适合用于搜索引擎构建倒排索引的分词，粒度比较细\n",
    "seg_list = jieba.cut_for_search(str_1) # 搜索引擎模式\n",
    "print \"search:\" + \"/\".join(seg_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'\\u4e0a\\u6c7d', u'\\u96c6\\u56e2', u'\\u7684', u'\\u5149\\u4e4b\\u7ffc', u'\\u8f66\\u578b', u'\\uff0c', u'\\u9500\\u91cf', u'\\u5982\\u4f55', u'\\uff1f']\n"
     ]
    }
   ],
   "source": [
    "# jieba.cut 以及 jieba.cut_for_search 返回的结构都是一个可迭代的 generator，\n",
    "# 可以使用 for 循环来获得分词后得到的每一个词语(unicode)，或者用jieba.lcut 以及 jieba.lcut_for_search 直接返回 list\n",
    "seg_list = jieba.lcut(str_1, cut_all=False)\n",
    "print seg_list "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载词典"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=green size=3>关于【词频】：1.对于”交叉词汇“而言，分词要看用户字典的两个词的权重大小，比如当语句中出现”下官云飞龙”，根据“下官云“和”云飞龙“的词频不同来进行取舍;2.优先级：”全集字符串“的分词优先级高于词频，如果用户字典中“下官云飞龙”的词频即使很低，“下官云“和”云飞龙“词频高，也会优先分割为“下官云飞龙”。</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add dict before:下官云/飞龙是/创新办/主任/也/是/云计算/方面/的/专家\n",
      "add dict after:下官云/飞龙是/创新办/主任/也/是/云计算/方面/的/专家\n"
     ]
    }
   ],
   "source": [
    "#　jieba加载词典是一劳永逸类型的，除非重启程序，重新运行一次程序。\n",
    "test_str = '下官云飞龙是创新办主任也是云计算方面的专家'\n",
    "seg_str = jieba.cut(test_str)\n",
    "print 'add dict before:' + '/'.join(seg_str)\n",
    "jieba.load_userdict('userdict')\n",
    "seg_str_1 = jieba.cut(test_str)\n",
    "print 'add dict after:' + '/'.join(seg_str_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 调整词典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "下官云/飞龙是/创新办主任/也/是/云计算/方面/的/专家\n",
      "下官云/飞龙是/创新办/主任/也/是/云计算/方面/的/专家\n",
      "下官云/飞龙是/创新办/主任/也/是/云计算/方面/的/专家\n"
     ]
    }
   ],
   "source": [
    "# 使用 add_word(word, freq=None, tag=None) 和 del_word(word) 可在程序中动态修改词典。\n",
    "jieba.add_word('创新办主任')\n",
    "seg_list = jieba.cut(test_str)\n",
    "print '/'.join(seg_list)\n",
    "jieba.del_word('创新办主任')\n",
    "seg_list = jieba.cut(test_str)\n",
    "print '/'.join(seg_list)\n",
    "# 使用 suggest_freq(segment, tune=True) 可调节单个词语的词频，使其能（或不能）被分出来。\n",
    "jieba.suggest_freq('飞龙是', True)\n",
    "seg_list = jieba.cut(test_str)\n",
    "print '/'.join(seg_list)\n",
    "# 注意：自动计算的词频在使用 HMM 新词发现功能时可能无效"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize：返回词语在原文的起止位置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word 永和\t\t start: 0 \t\t end:2\n",
      "word 服装\t\t start: 2 \t\t end:4\n",
      "word 饰品\t\t start: 4 \t\t end:6\n",
      "word 有限公司\t\t start: 6 \t\t end:10\n",
      "<type 'tuple'>\n"
     ]
    }
   ],
   "source": [
    "# 注意，输入参数只接受 unicode\n",
    "result = jieba.tokenize(u'永和服装饰品有限公司')\n",
    "for tk in result:\n",
    "    print(\"word %s\\t\\t start: %d \\t\\t end:%d\" % (tk[0],tk[1],tk[2]))\n",
    "print type(tk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word 永和\t\t start: 0 \t\t end:2\n",
      "word 服装\t\t start: 2 \t\t end:4\n",
      "word 饰品\t\t start: 4 \t\t end:6\n",
      "word 有限\t\t start: 6 \t\t end:8\n",
      "word 公司\t\t start: 8 \t\t end:10\n",
      "word 有限公司\t\t start: 6 \t\t end:10\n"
     ]
    }
   ],
   "source": [
    "#搜索模式\n",
    "result = jieba.tokenize(u'永和服装饰品有限公司', mode='search')\n",
    "for tk in result:\n",
    "    print(\"word %s\\t\\t start: %d \\t\\t end:%d\" % (tk[0],tk[1],tk[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【糟糕】的权重是： 2.98869187572\n",
      "【运气】的权重是： 1.49434593786\n",
      "【心情】的权重是： 1.49434593786\n",
      "【怎么样】的权重是： 1.49434593786\n",
      "【今天】的权重是： 1.49434593786\n"
     ]
    }
   ],
   "source": [
    "import jieba.analyse\n",
    "jieba.analyse.set_idf_path(\"chenbofeng_userdict\")\n",
    "keywords_list = jieba.analyse.extract_tags(sentence=u'今天的运气真的很糟糕，我的心情也跟着很糟糕，你怎么样', topK=5, withWeight=True, allowPOS=()) \n",
    "for i in keywords_list:\n",
    "    print '【{0}】的权重是： {1}'.format(i[0].encode('utf-8'), i[1])\n",
    "a=1.70782392899"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
